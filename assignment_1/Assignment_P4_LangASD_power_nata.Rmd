---
title: "Assignment 1 - Language Development in ASD - part 4"
author: "Katarina Michelova"
date: "August 10, 2017"
output: html_document
---


## Welcome to the fourth exciting part of the Language Development in ASD exercise

In this exercise we will assess how many participants we would need to adequately replicate our findings (ensuring our sample size is adequate, our alpha at 0.05 and our beta at 0.8).

### Exercise 1

How much power does your study have (if your model estimates are quite right)?
- [GitHub]Load your dataset, fit your favorite model, assess power for your main effects and interactions of interest.
- Report the power analysis and comment on what you can (or cannot) use its estimates for.
```{r}
library(lmerTest)
library(Metrics)
library(stringr)
library(dplyr)
#install.packages("caret")
library(data.table)
library(ggplot2)
library(stringi)
library(stringr)
library(tidyverse)
library(zoo)
library(plyr)
library(MuMIn)
library(modelr)
library(ModelMetrics)
#install.packages("pwr")
library(pwr)
#install.packages("simr")
library(simr)

setwd("C:/Users/natal/Google Drive/study/3 semester/EM3/assignment1")

```


```{r}

full_data <- read.csv("full_data.csv")
full_data$X <- NULL
train_data <- read.csv("demo_test_real.csv")
train_data$SUBJ <- as.integer(train_data$SUBJ )


model <- lmer(CHI_MLU~VISIT* Diagnosis+ I(VISIT^2)*Diagnosis +I(VISIT^3)* Diagnosis +(1|SUBJ), full_data)
summary(model)


#power for predictor VISIT -72.00%, effect size for VISIT is 0.78 
powerV = powerSim(model ,fixed("VISIT", method = "t"),nsim=200)
powerV

#Power - 25.50%, effect size - 0.49 
powerD = powerSim(model ,simr::fixed("DiagnosisB", method = "t"),nsim=200)
powerD
#tu si mala model1
#power 51.5 %, effect size - -0.81
powerI = powerSim(model, test = fixed("VISIT:DiagnosisB", method = "t"),nsim=200)
powerI 

#check for NA
#is this enough for power analysis?
#1.2 effect size, 35 - sample size, variabilty?

```


### Exercise 2

How would you perform a more conservative power analysis?
- Identify and justify a minimum effect size for each of your relevant effects
- [GitHub] take the model from exercise 1 and replace the effects with the minimum effect size that you'd accept. - ask?
- [GitHub] assess the power curve by Child.ID, identifying an ideal number of participants to estimate each effect - how we can identify additional participants?
- [GitHub] if your power estimates do not reach an acceptable threshold simulate adreshold?
- Report the power analysis and comment on what you can (or cannot) use its estimates for.

```{r}

model1 <- lmer(CHI_MLU~VISIT*Diagnosis + (1+VISIT|SUBJ), full_data)

fixef(model)["VISIT"] <- 0.1
fixef(model)["DiagnosisB"] <- 0.1

powerCurveV = powerCurve(model,test = fcompare(CHI_MLU~VISIT), along =  "SUBJ", nsim=100)
 plot(powerCurveV)

 
powerCurveD = powerCurve(model,fixed("DiagnosisB"),along="SUBJ", nsim=200)
plot(powerCurveD)

model_ext_class <- extend(model, along="SUBJ", n=200)
powerCurveV = powerCurve(model_ext_class,fixed("VISIT"),along="SUBJ", nsim=200)
plot(powerCurveV)

powerI2 = powerSim(model, test = fixed("DiagnosisB:I(VISIT^2)", method = "t"),nsim=2)
powerI2 #100%

powerI3 = powerSim(model, test = fixed("DiagnosisB:I(VISIT^3)", method = "t"),nsim=2)
powerI3 #100%

```



### Exercise 3

Assume you have only the resources to collect 30 kids (15 with ASD and 15 TDs). Identify the power for each relevant effect and discuss whether it's worth to run the study and why

```{r}
#Changing number of classes and participants per class
model_final <- extend(model, along="SUBJ", n= 15)
model_final <- extend(model_final, within="class+treat+time", n=10)

sim_final <- powerSim(model_final, nsim=100, test = fcompare(y~time))
sim_final


```


